"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ü–µ–Ω –ø–æ –±—Ä–µ–Ω–¥–∞–º —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π API WB."""
import asyncio
import json
import sys
from pathlib import Path
from typing import Dict, List

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from loguru import logger
from src.parsers.wb_parser import WildberriesParser
try:
    from src.utils.logger import setup_logger
except ImportError:
    def setup_logger(logs_dir, debug=False):
        logger.info("–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ")


def load_brands_config() -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±—Ä–µ–Ω–¥–æ–≤ –∏–∑ brands_config.json."""
    config_file = project_root / "config" / "brands_config.json"
    
    if not config_file.exists():
        logger.error(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return {}
    
    with open(config_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_env_config() -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ .env —Ñ–∞–π–ª–∞."""
    try:
        from dotenv import load_dotenv
        import os
        
        env_file = project_root / ".env"
        if env_file.exists():
            load_dotenv(env_file)
        
        # –°–æ–±–∏—Ä–∞–µ–º cookies –∏–∑ .env
        cookies_parts = []
        cookie_names = [
            "wbx-validation-key",
            "_cp",
            "routeb",
            "x_wbaas_token",
            "_wbauid"
        ]
        
        for cookie_name in cookie_names:
            cookie_value = os.getenv(f"WB_COOKIE_{cookie_name.replace('-', '_').upper()}")
            if cookie_value:
                cookies_parts.append(f"{cookie_name}={cookie_value}")
        
        cookies_string = "; ".join(cookies_parts) if cookies_parts else None
        
        return {
            "dest": int(os.getenv("WB_DEST", "-3115289")),
            "spp": int(os.getenv("WB_SPP", "30")),
            "cookies": cookies_string,
        }
    except Exception:
        return {"dest": -3115289, "spp": 30, "cookies": None}


async def parse_all_brands():
    """–ü–∞—Ä—Å–∏—Ç –≤—Å–µ –±—Ä–µ–Ω–¥—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    logs_dir = project_root / "logs"
    logs_dir.mkdir(exist_ok=True)
    setup_logger(logs_dir, debug=False)
    
    logger.info("=" * 70)
    logger.info("–ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω –ø–æ –±—Ä–µ–Ω–¥–∞–º —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π API WB")
    logger.info("=" * 70)
    
    brands_config = load_brands_config()
    env_config = load_env_config()
    
    if not brands_config:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±—Ä–µ–Ω–¥–æ–≤")
        return []
    
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(brands_config)}")
    
    parser = WildberriesParser(
        api_key="",
        cabinet_name="",
        cabinet_id="",
        request_delay=0.1
    )
    
    all_results = []
    dest = env_config["dest"]
    spp = env_config["spp"]
    cookies = env_config.get("cookies")
    
    if cookies:
        logger.info("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è cookies –∏–∑ .env —Ñ–∞–π–ª–∞")
    else:
        logger.warning("Cookies –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ .env - –∑–∞–ø—Ä–æ—Å—ã –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –∞–Ω—Ç–∏–±–æ—Ç–æ–º")
    
    for brand_name, brand_data in brands_config.items():
        brand_id = int(brand_data["brand_id"])
        logger.info(f"\n{'='*70}")
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±—Ä–µ–Ω–¥–∞: {brand_name} (ID: {brand_id})")
        logger.info(f"{'='*70}")
        
        try:
            results = await parser.parse_brand_catalog(
                brand_id=brand_id,
                brand_name=brand_name.upper(),
                dest=dest,
                spp=spp,
                fsupplier=brand_data.get("fsupplier"),
                cookies=cookies
            )
            
            all_results.extend(results)
            logger.success(f"‚úì –ë—Ä–µ–Ω–¥ {brand_name}: –ø–æ–ª—É—á–µ–Ω–æ {len(results)} –∑–∞–ø–∏—Å–µ–π")
            
        except Exception as e:
            logger.error(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±—Ä–µ–Ω–¥–∞ {brand_name}: {e}")
            logger.exception("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")
            continue
    
    return all_results


def export_results(results: List[Dict], output_dir: Path):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel."""
    if not results:
        logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
        return
    
    try:
        import pandas as pd
        from datetime import datetime
        from openpyxl.utils import get_column_letter
        
        df = pd.DataFrame(results)
        
        sort_columns = []
        if 'brand_name' in df.columns:
            sort_columns.append('brand_name')
        if 'cabinet_name' in df.columns:
            sort_columns.append('cabinet_name')
        if 'product_name' in df.columns:
            sort_columns.append('product_name')
        
        if sort_columns:
            df = df.sort_values(sort_columns, ascending=[True] * len(sort_columns))
        
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"wb_brands_prices_{timestamp}.xlsx"
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Prices')
            
            worksheet = writer.sheets['Prices']
            
            for idx, col in enumerate(df.columns, 1):
                max_length = max(
                    df[col].astype(str).map(len).max(),
                    len(str(col))
                )
                col_letter = get_column_letter(idx)
                worksheet.column_dimensions[col_letter].width = min(max_length + 2, 50)
        
        logger.success(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
        logger.info(f"üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")
        logger.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns.tolist())}")
        
        if 'price_basic' in df.columns:
            filled = df['price_basic'].notna().sum()
            logger.info(f"üí∞ –ó–∞–ø–æ–ª–Ω–µ–Ω–æ –±–∞–∑–æ–≤—ã—Ö —Ü–µ–Ω: {filled} –∏–∑ {len(df)} ({filled/len(df)*100:.1f}%)")
        
        if 'price_product' in df.columns:
            filled = df['price_product'].notna().sum()
            logger.info(f"üí∞ –ó–∞–ø–æ–ª–Ω–µ–Ω–æ —Ü–µ–Ω –ø—Ä–æ–¥—É–∫—Ç–∞: {filled} –∏–∑ {len(df)} ({filled/len(df)*100:.1f}%)")
        
        if 'brand_name' in df.columns:
            logger.info("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±—Ä–µ–Ω–¥–∞–º:")
            brand_stats = df.groupby('brand_name').size()
            for brand, count in brand_stats.items():
                logger.info(f"  {brand}: {count} –∑–∞–ø–∏—Å–µ–π")
        
        if 'cabinet_name' in df.columns:
            logger.info("\nüè¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–±–∏–Ω–µ—Ç–∞–º:")
            cabinet_stats = df.groupby('cabinet_name').size()
            for cabinet, count in cabinet_stats.items():
                logger.info(f"  {cabinet}: {count} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        logger.exception("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    try:
        results = await parse_all_brands()
        
        logger.info("\n" + "=" * 70)
        logger.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(results)}")
        logger.info("=" * 70)
        
        output_dir = project_root / "output"
        export_results(results, output_dir)
        
        return 0
        
    except KeyboardInterrupt:
        logger.warning("–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 1
        
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.exception("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")
        return 1


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
